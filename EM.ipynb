{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3ec79b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./archive/EuroMillions_numbers.csv', delimiter=';')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "474aa2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mediaN1 = df['N1'].mean()\n",
    "modaN1 = df['N1'].median()\n",
    "mediaN2 = df['N2'].mean()\n",
    "modaN2 = df['N2'].median()\n",
    "mediaN3 = df['N3'].mean()\n",
    "modaN3 = df['N3'].median()\n",
    "mediaN4 = df['N4'].mean()\n",
    "modaN4 = df['N4'].median()\n",
    "mediaN5 = df['N5'].mean()\n",
    "modaN5 = df['N5'].median()\n",
    "\n",
    "mediaE1 = df['E1'].mean()\n",
    "modaE1 = df['E1'].median()\n",
    "mediaE2 = df['E2'].mean()\n",
    "modaE2 = df['E2'].median()\n",
    "\n",
    "print('La media de (1-50) resultados del primer número es: ',mediaN1,' y la moda es: ',modaN1,'\\n')\n",
    "print('La media de (1-50) resultados del primer número es: ',mediaN2,' y la moda es: ',modaN2,'\\n')\n",
    "print('La media de (1-50) resultados del primer número es: ',mediaN3,' y la moda es: ',modaN3,'\\n')\n",
    "print('La media de (1-50) resultados del primer número es: ',mediaN4,' y la moda es: ',modaN4,'\\n')\n",
    "print('La media de (1-50) resultados del primer número es: ',mediaN5,' y la moda es: ',modaN5,'\\n')\n",
    "\n",
    "print('La media de (1-7) resultados de la primera estrella es: ',mediaE1,' y la moda es: ',modaE1,'\\n')\n",
    "print('La media de (1-7) resultados de la segunda estrella es: ',mediaE2,' y la moda es: ',modaE2,'\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c05a1b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_procesados_1 = df.drop(['Winner', 'Gain', 'Date'], axis=1)\n",
    "#datos_procesados_1.loc[1]\n",
    "#datos_procesados_1.columns.values\n",
    "datos_procesados_1.columns.values\n",
    "#datos_procesados_1.iloc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2115c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prc_num(n1=None, n2=None, n3=None, n4=None, n5=None):\n",
    "    numbers = []\n",
    "    keys = [['n1', n1], ['n2', n2], ['n3', n3], ['n4', n4], ['n5', n5]]\n",
    "    i=0\n",
    "    for i in range(len(keys)):\n",
    "        value = 1/50#keys[i][1]50\n",
    "        \n",
    "        print('El número'+str(keys[i][1])+'\\nTiene una probabilidad de: '+str(value))\n",
    "        \n",
    "prc_num(1,4,3,3,45)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44caa310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prc_star(e1=None, e2=None):\n",
    "    stars = []\n",
    "    keys = [['e1', e1], ['e2', e2]]\n",
    "    i=0\n",
    "    for i in range(len(keys)):\n",
    "        value = 1/12#keys[i][1]50\n",
    "        \n",
    "        print('La estrella '+str(keys[i][1])+'\\nTiene una probabilidad de: '+str(value))\n",
    "        \n",
    "prc_star(1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9c6ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries needed to create the Custom Scaler\n",
    "# note that all of them are a part of the sklearn package\n",
    "# moreover, one of them is actually the StandardScaler module, \n",
    "# so you can imagine that the Custom Scaler is build on it\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create the Custom Scaler class\n",
    "\n",
    "class CustomScaler(BaseEstimator,TransformerMixin): \n",
    "    \n",
    "    # init or what information we need to declare a CustomScaler object\n",
    "    # and what is calculated/declared as we do\n",
    "    \n",
    "    def __init__(self,columns):\n",
    "        \n",
    "        # scaler is nothing but a Standard Scaler object\n",
    "        self.scaler = StandardScaler()\n",
    "        # with some columns 'twist'\n",
    "        self.columns = columns\n",
    "        self.mean_ = None\n",
    "        self.var_ = None\n",
    "        \n",
    "    \n",
    "    # the fit method, which, again based on StandardScale\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X[self.columns], y)\n",
    "        self.mean_ = np.mean(X[self.columns])\n",
    "        self.var_ = np.var(X[self.columns])\n",
    "        return self\n",
    "    \n",
    "    # the transform method which does the actual scaling\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        # record the initial order of the columns\n",
    "        init_col_order = X.columns\n",
    "        \n",
    "        # scale all features that you chose when creating the instance of the class\n",
    "        X_scaled = pd.DataFrame(self.scaler.transform(X[self.columns]), columns=self.columns)\n",
    "        \n",
    "        # declare a variable containing all information that was not scaled\n",
    "        X_not_scaled = X.loc[:,~X.columns.isin(self.columns)]\n",
    "        \n",
    "        # return a data frame which contains all scaled features and all 'not scaled' features\n",
    "        # use the original order (that you recorded in the beginning)\n",
    "        return pd.concat([X_not_scaled, X_scaled], axis=1)[init_col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db5bdbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EM_scaler = StandardScaler()\n",
    "unscaled_inputs = df.iloc[:,1:8]\n",
    "columns_to_scale = ['n1',\n",
    "       'n2', 'n3', 'n4',\n",
    "       'n5', 'e1', 'e2']\n",
    "unscaled_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2166a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EM_scaled = CustomScaler(columns_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "112ff81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EM_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dc061bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "EM_scaler.fit(unscaled_inputs)\n",
    "scaled_inputs = EM_scaler.transform(unscaled_inputs)\n",
    "scaled_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66c38143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e642c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
